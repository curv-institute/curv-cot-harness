# Experiment 002 Output — Multi-target Baseline

## Run Summary

**Run name:** v0.1.1-baseline-multitarget-claude-20260120
**Dataset:** eval/datasets/arithmetic-60.jsonl (60 items)
**Proposer:** Claude Sonnet (100% accuracy)
**Targets:** Opus, Sonnet (as target), Haiku

## Results

### Agreement
- Pairwise agreement rate (with trace): **1.0000**
- Pairwise agreement rate (no trace): **0.9667**
- Δ agreement: **+0.0333**

### Accuracy by Target Model

| Model | No Trace | With Trace | Transfer Gain |
|-------|----------|------------|---------------|
| opus | 1.0000 | 1.0000 | +0.0000 |
| sonnet_tgt | 1.0000 | 1.0000 | +0.0000 |
| haiku | 0.9500 | 1.0000 | +0.0500 |

### All-Target Agreement Outcomes

| Condition | Agree-on-Correct | Agree-on-Wrong |
|-----------|------------------|----------------|
| With Trace | 60 | 0 |
| No Trace | 57 | 0 |

## Summary Questions (per experiment spec)

1. **Did trace injection increase pairwise agreement across targets?**
   Yes (Δ = +0.0333, from 96.7% to 100%)

2. **Did trace injection increase per-target accuracy?**
   - Opus: No change (already 100%)
   - Sonnet: No change (already 100%)
   - Haiku: Yes (+5%, from 95% to 100%)

3. **Did agreement-on-wrong (consistent-wrong) increase?**
   No (0 in both conditions)

## Commit

Commit `82b3c3ac` pushed to origin/main.
